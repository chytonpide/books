# Data Integrity: What You Read Is What You Wrote
데이터 무결성은 사용자에게 적절한 수준의 서비스를 제공하기 위한 데이터스토어의 접근성과 정확성을 측정하는 측도이다.
데이터 무결성을 고려할 때 중요한 것은 사용자는 클라우의 서비스에 엑세스 가능해야하고, 데이터에 대한 사용자의 엑세스는 더 중요하다는 것이다. 

## Data Integrity's Strict Requirements
99.99% 가용성은 꽤 높은 기준이지만 어떤 아티팩트의 데이터가 99.99% 가 정확하다면 치명적인 결과를 초래한다.
어떤 아티팩트가 1년에 딱 한번 손상되고 그것이 복구할수 없다면 그 아티팩트 uptime은 그대로 사라진다.
만약 사용자가 영향을 받기전에 아티팩트의 손상이 감지되어서 수정되고 서비스가 30분 이내에 지개되었다면 99.99% 의 가용성을 유지할 수 있다.
이렇듯 우수한 데이터 무결성의 비결은 사전 감지와 신속한 복원 복구이다.

### Choosing a Strategy for Superior Data Integrity (뛰어난 데이터 무결성을 위한 전략 선택)
클라우드 어프리케이션은 다음 과 같은 속성 조합을 최적하 하려고 한다. Uptime, Latency, Scale, Velocity, Privacy
많은 클라우드 어프리케이션은 ACID 와 BASE 의 혼합 위에서 위의 속성의 요구사항을 충족하기 위해 계속 발전한다.
이 조합에는 트레이드오프가 발생한다 예를들어 Velocity 를 높이면, 다른 속성들이 희생될 수 있다.
Velocity 를 위해 다양한 데이터 스토어를 조합해서 사용하고 이로인한 복잡도가 증가할 경우 데이터 무결성을 위해, 조기 탐지와 같은 시스템이 필요할 수 있다.
데이터무결성을 위해 어느정도 리소스를 투자해야할지 결정해야 한다.

### Backups Versus Archives
백업이 중요한게 아니라 데이터 복구가 중요하다. 그러므로 진짜 백업과 아카이브는 구분되어야 한다.
백업은 어플리케이션으로 다시 불러올수 있지만 아카이브는 그렇지 않다.
아카이브는 감사와 발견등을 위해 장기간에 걸쳐서 데이터를 보관하는 것이다.

### Requirements of the Cloud Environment in Perspective (클라우드 환경의 요구사항 바르게 보기)
클라우드 환경은 고유의 기술적 도전이 있다. 다운타임이 없는 서비스는, 다른 버전의 비지니스 로직이 데이터에 작용할 수도 있고, 
상호작용 하는 서비스의 버전이 호환되지 않으면서 데이터를 부패 시키는 경우도 있다.
서비스 제공업체는 데이터 지역성과 캐싱, 백업 및 복구, 일관성 같은 속성을 충분히 이해하는 API를 제공해야 한다.




## Google SRE Objectives in Maintaining Data integrity and Availability (데이터 가용성과 무결성관리에 대한 구글의 목표)
측정가능한 지표를 통해서 목표 달성에 노력하려고 한다.
SRE는 테스트를 통해 시스템과 프로세스의 기대치를 설정하는데 사용하는 주요 지표를 정의한다.
그리고 실제 이벤트 중에 성과를 추적하기 위해 지표를 정의한다.

### Data Integrity Is the Means; Data Availability Is the Goal
데이터 무결성은 데이터의 수명동안의 데이터의 정확성과 일관성을 의미한다.
그러나 사용자 입장에서 정기적인 가용성이 없는 데이터 무결성은 사실상 데이터가 없는것 과 같다.

### Delivering a Recovery System, Rather Than a Backup System
백업은 지루한 작업으로 치부된다. 데이터가 유실될 위험이 적더라도 그것이 실제로 일어났을때의 임팩트는 회사의 명운을 좌지우지 할 정도로 크다.
복구에 초점을 맞추고 백업은 그를 위한 세금으로 바라보는것이 좋다.
팀은 여러 실패 모드에서 데이터 가용성에 대한 SLO를 정의하고 SLO를 달성하기 위한 능력을 연습하고 입증한다. 

### Types of Failures That Lead to Data Loss
데이터 손실을 이끄는 실패의 타입은 총 24 개이고 이는, Root cause, Scope, Rate 세가지 팩터의 조합이다.
어떤 특정한 실패모드에 효과적인 전략이 다른 실패모드에는 도움이 될 수 없기 때문에 진정으로 효과적인 복구 전략은 모든 실패 모드를 설명할 수 있어야 한다.
참조 무결성 손실은 대부분의 경우 어플리케이션 버그였다.
복구 솔루션이 point-in-time-recovery 를 지원하면 좋겠지만 만은 경우 tiered backup strategy(계층형 백업 전략) 으로 타협한다.

### Challenges of Maintaining Data Integrity Deep and Wide (깊고 넓게 데이터 무결성을 관리할 때의 도전)
데이터 무결성 프로그램을 설계할때, 복제 및 이중화(Redundancy)는 복구용이성이 아님을 인식해야 한다.

#### Scaling issues: Fulls, incrementals, and the competing forces of backups and restores
replication 은 데이터 손실을 보호할 수 없다. 그냥 문제가 복제될 뿐이다.
데이터베이스의 사본이 있더라도 더 낮은 레벨에서 이 사본들을 품는 시스템 문제가 발생하는 경우 데이터 손실을 보호할 수 없다. 
따라서 다양한 구성요소에 데이터를 저장해야 한다.
데이터의 최신성과 복구 완성소는 포괄적인 데이터 보호와 경쟁한다.
스택의 아래로 내려갈수록 백업을 만드는데 걸리는 시간이 오래 걸리고, 사본을 만드는 빈도는 줄어든다.
따라서 낮은 스택에서의 복구를 한다면 최신 데이터를 복구 할 수 없는 상황이 발생한다.

#### Retention
점진적으로 데이터 손실이 일어나는 경우 시간이 지난 후에야 그것을 알 수 있는 경우가 있기 때문에 보존 기간을 어떻게 설정할지 고려해야 한다.




## How Google SRE Faces the Challenges of Data Integrity (구글은 어떻게 데이터 무결성 도전들에 맞섰는가)
대규모 데이터 무결성 보장을 위해서 상호 보완적 이지만 결합되지 않은 여러 방법을 사용한다.

### The 24 Combinations of Data Integrity Failure Modes
심층 방어(Defense in depth)는 여러 레이어로 구성되며, 연속적인 방어 레이어는 점점 더 일반적이지 않은 데이터 손실을 방어한다.
첫번째 레이어는 soft deletion 이고, 두번째 레이어는 백업과 그와 연관된 복구 방법, 세번째 레이어는 정기적인 데이터 검사: 조기 감지 이다.

### First Layer: Soft Deletion
개발 속도가 빠를 때 대부분의 데이터 손실과 부패는 어플리케이션 버그로 설명할 수 있다.
휴지통 기능: 유저가 자신의 데이터를 삭제할 수 있는 프러덕터의 경우에 유저에게 un-deletion 기능을 제공하는게 운영측의 부담을 줄일 수 있다.
soft deletion: 유저에게는 보이지 않지만, 운영측에서는 이 데이터를 사용, 복구 할 수 있도록 하면, 어카운트 하이제킹 같은 상황에 대응할 수 있음으로 운영측의 부담을 줄일 수 있다.
기존 코드에 익숙하지 않은 어플리케이션 개발자가 배치작성등으로 데이터를 삭제 하는것을 방지할 수 있다. (soft deletion 을 우회하지 못하도록 인터페이스를 설계해야 한다. ) 
lazy deletion: 추가적인 soft deletion 계층. 어플리케이션 레이어가 아니라 스토리지 시스템에 의해서 제어됨.

### Second Layer: Backups and Their Related Recovery Methods
이 레이어에서 중요한건 백업이 아니라 복구다. 
백업이 복구에 도움이 되기 위한 시나리오는 다음을 구술해야 한다. 백업 및 복구방법, 복원 지점 설정 빈도, 백업 위치, 백업 보관 기간.
전체 백업은 컴퓨팅 부담이 되기 때문에 증분을 백업에 추가하는 방식을 사용할 수 있다.

24가지 조합의 데이터 무결성 실패 방어에 대한 조언을 요약하면, 합리적인 비용으로 넓은 시나리오를 해결하려면 단이 분리된 백업 전략이 필요하다는 것이다.
첫번째 단(tier)은, 라이브 데이터 스토어와 가까운곳에 빈번하고 신속하게 복원되는 백업으로 구성된다.
이 단은 소프트웨어 버그 및 개발자 실수의 대부분의 시나리오를 커버한다.
두번째 단은, 로컬 사이트에 한자리 또는 두자릿수의 날동안 보관되는 백업이다. 첫번째 단에 의존하기에는 너무 늦게 발견한 어플리케이션 버그로 부터 보호한다.  
세번째 단은, 오프 사이트에 보관되는 다른 미디엄을 사용하는 백업으로, 데이터센터의 장애나 분산 파일 시스템의 손상같은 사이 수준의 문제에 대한 보호를 제공한다.

### Overarching Layer: Replication
백업도 다른 위치에 사본들을 두는게 좋다. 이중화를 사용하는 경우에도 많이 사용되는 전략을 골라라.

### 1T Versus 1E: Not "Just" a Bigger Backup (단지 그냥 더 큰 백업은 아니다.)
데이터 사이즈의 단위가 terabytes 에서 exabytes 로 증가할때, 기존 프로세스와 사례들은 잘 확장되지 않는다.
기가바이트 단위 데이터를 처리하는건 간단한 일 이지만, 700petabytes 를 처리해야 한다고 할때 SATA2 의 스팩인 300MB/s 로는,
한번 전체를 훑는데 80년이 걸린다. 따라서 신뢰 지점을 만들고 증분을 더해가는 방법이 사용된다.
중요한 것은 복구이다. 하루에 하나씩 증분을 만든다고 치면 3년이 지나면 1000개가 넘는 증분이 생기고,
복구를 위해 이것들을 순차적으로 처리하는 일은 위험성이 크다.
이때 부하를 분산하는 방법을 사용할 수 있다. 데이터 잘 조각내면 처리를 병렬로 처리할 수 있다.

### Third Layer: Early Detection
나쁜 데이터는 가만이 있지 않고 전파된다. 시간이 지날수록 복구는 어려워짐으로 일찍 알수록 완벽한 복구를 할 가능성이 높아진다.

#### Challenges faced by cloud developers
개발 속도가 빠른 클라우드 어플리케이션은 런다음에 다음과 같은 데이터 무결성 도전에 직면한다.
데이터 스토어간 참조 무결, 스키마 변경, 오래된 코드, 다운타임 없는 마이그레이션, 진화하는 통합 포인트.
데이터의 새로운 관계를 추적하기 위한 의식적인 엔지니어링 노력이 없다면 서비스 데이터의 품질은 시간이 저하될 수 밖에 없다.
개발자는 분산 일관성을 제공하는 storage API 를 사용할 수 있다. 이 API 는 Paxos 같은 분산 합의 알고리즘을 구현하고 있다.
알고리즘은 완벽 할 수 있지만 그것의 구현은 그렇지 않을 수 있다. 특정 머신이 특정한 타이밍에 특정한 방식으로 장애를 일으키면 예측 할 수 없는 동작이 발생하고,
규모의 원리에 의해서 규모가 클수록 이러한 상황에 의해서 어플리케이션이 영향을 받을 수 있다.
Paxos 의 구현이 이렇다면 결과적 일관성을 지원하는 Bigtable 과 같은 스토리지에서는 이런 일들이 더 일반적일 것이다.

#### Out-of-band data validation
유저의 눈에 보이기 전에 품질의 저하를 방지하고, 복구가 불가능한 상태가 되기전에 감지하려면, 어플리케이션 안팎에 대역외(out of band, 범위 바깥에서 이루어지는) 검사 시스템이 필요하다.
데이터 유효성 검사는 map-reduce나 하둡으로 구현된다.
데이터 유효성 감사를 도입하는것은 단기적으로는 개발 속도를 늦출 수 있지만, 데이터 손상 버그가 프러덕션 환경에서 발견되지 않을 가능성이 높지 않다는 사실을 장기적으로 봤을 때 개발 속도를 올린다.
out of band 검증은 오직 유저에게 큰 영향을 미치는 불변식만 검증 해야한다.
out-of-band data validation framework 의 구현 및 관리는 중앙 집중화된 별도의 팀이 맡고, 각 프러덕트 팀에서 이 프레임워크에 검증 로직을 설정 관리하는 것이 효율적이다. 

### Knowing That Data Recovery Will Work
복구 의존성이 부서진 상태라는 것을, 데이터 복구를 시도할 때 할게 되어서는 안된다.
이러한 취약성을 극복하기 위해서 평소 운영에서 복구 프로세스를 주기적으로 테스트하고, 복구 프로세스가 실패했을 때 경고가 발생하도록 해야한다.
이러한 테스트들은 자동화 되어야 한다. 구글은 복구 프로세스에 대한 테스트에서 프로세스의 실패를 발견 했고, 이것들은 테스트에서 발견하지 못했다면
실제 복구가 필요한 상황에서 발견되었을 것이다. 실패는 피할 수 없고 테스트를 통해 실제 재앙이 발생하기 전에 그것을 알 수 있다면 피해를 막을 수 있다.

## Case Studies
### Gmail: Restore from GTape
대량의 유저 데이터 손실이 있었다. 백업 서브시스템이 실패했지만 Gtape를 통해서 복구할 수 있었다.
이런 복구는 사전에 충분히 연습이 되어 있었기 때문에 복구에 걸리는 시간을 추정할 수 있었고 실제로 복구를 성공적으로 완료할 수 있었다.
디스크에 대한 디바이스 드라이버와 파일 시스템의 제로데이 취약성에서 시스템을 지킬 수 있었고 심층 방어 원칙과 이를 위한 투자가 효과가 있다는 것을 입증 할 수 있었다.
### Google Music: Runaway Deletion Detection 
유저로부터 트랙이 스킵된다는 리포트를 받았다. 
참조가 누락된 것을 발견하고 데이터를 수정한 다음 조사를 이어갔고 데이터 삭제 파이프라인이 대량의 오디오에 대한 참조를 삭제하고 있다는 것을 발견했다.
피해규모를 평가했다. 더이상 피해가 커지지 않도록 파이프라인의 동작을 정시시킨 다음, MapReduce job 을 통해서 구체적인 피해 데이터를 확인했다.
60만 오디오 참조가 제거되었고 버그로인한 삭제가 한달도 전에 시작된 것을 알게 되었다.
근본 원인 찾기를 시작했다. 떨어진 곳에서 tape를 보관하고 있었기 때문에 복구에 시간이 더 걸릴 수 있었고 원인 찾기와 복구준비를 병렬로 수행했다.
다행히도 일주일 전에 연간 재해복구 연습이 있어서 복구작업의 진행이 순조로웠다. 몇주에 걸쳐서 데이터 복구를 마쳤다.
원인은 데이터 삭제 파이프라인의 경쟁상태로 인해 잘못된 데이터가 삭제되는 것 이었다.
원인을 발견한 후 파이프라인을 재 설계했고 이런한 문제를 감지하기 위해 모니터링 및 경고 시스템을 개선했다.

## General Principles of SRE as Applied to Data Integrity
### Beginner's Mind
대규모의 복잡한 서비스에는 완전히 파악할 수 없는 버그가 내제되어 있다. 특정한 방식으로 실패하지 않을 거라고 말할 정도로 충분히 복잡한 시스템을 이해 했다고 생각하지 말아라.
데이터 무결성을 위해 시스템을 신뢰하지만 검증해야하고 심층 방어를 적용해야 한다.
### Trust but Verify
의존하는 모든 API가 항상 완벽하게 작동하지는 않는다. 대역외 데이터 검사를 통해서 데이터의 가장 중요한 요소를 검사해야 한다.
### Hope Is Not a Strategy
연습되지 않는 시스템 컴퍼넌트가 너가 가장 그게 필요로 할 때 실패한다. 데이터 복구 작업을 계속 해서 검증해야 하고 이것을 자동화 해야 한다.
### Defense in Depth
데이터 무결성 이슈를 해결 할 수 있게 하기 위해서는 이슈를 빨리 찾아야 한다. 모든 전략은 변화 하는 환경에서 결국 실패하게 됨으로, 최고의 전략들은 다층이다.  

## Conclusion
데이터 가용성 이야말로 핵심이다. 수단에 집중하지 말고 최종 목표인 데이터 가용성에 집중해야 한다.
모든 것이 잘못 될 수 있다는 것을 인지하고 이것을 바탕으로 긴급 상황을 준비해야한다.
데이터 무결성을 위한 전략은 여러 단계에 존재해서 상호 보완할 수 있어야 하고 연습되고 자동적으로 테스트되어야 한다.
복구 절차를 계속해서 개선하면서, 복구가 아닌 예방으로 진화시켜야 한다.