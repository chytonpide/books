# 원리 (Principles)
이 섹션에서는 SRE 팀이 일반적으로 어떻게 일하는지를 뒷받침하는 원칙들—SRE 운영의 일반적인 영역에 영향을 미치는 패턴, 행동, 그리고 관심사들을—살펴본다.

--------------------

## 리스크 포용하기 (Embracing Risk)
SRE 는 넓은 시야에서 보면 에러 버짓이라는 수단을 사용해서 위험을 평가하고 수용하는 엔지니어링 방식이다.

### Managing Risk
리스크 관리에 관하여, 서비스의 신뢰성을 관리한다는 것은 리스크를 관리한다는 것이다. 
100% 가용성은 달성 불가능하고 유저가 원하지도, 알아 챌 수도 없다. (수치가 커질수록 달성을 위한 비용은 기하급수적으로 증가한다.)
따라서 서비스를 충분히 신뢰성 있게 만들되, 그 이상으로 만들지 않도록 한다.

### Measuring Service Risk
구글에서는 시스템의 특성을 대표할 수 있는 객관적인 지표를 식별해 내어서 목표를 설정함으로써 성능을 평가하고 변화를 추적한다.
하지만 리스크의 경우 여러 요인을 하나의 지표로 다루기는 힘들다.
다양한 시스템유형에 대해서 실용적이고 일관되게 다루기 위해서 구글은 예기치 않은 다운타임에 unplanned downtime 에 초점을 맞춘다.
time-based availability 라는 측정장법이 있지만 구글에서는 리퀘스트의 성공비율을 나타내는 aggregate availability 를 사용한다.  
```
availablity = successful requests / total requests
```
어플리케이션에서 각 리퀘스트의 중요도는 다르지만 요청의 성공률로 계산된 가용성은 사용자 관점에서 보는 다운타임을 합리적으로 근사하는 지표가 될 수 있다.
이 지표는 사용자에게 직접 서비스를 제공하지 않는 시스템에도 적용할 수 있고 이때, 리퀘스트의 성공과 실패 명확하게 정의되어 있다.
구글에서는 분기별로 서비스의 가용성 목표를 설정하고 실제 성과를 매주 또는 매일 추적한다.  

### Risk Tolerance of Services
서비스의 위험 감수 한계 밝혀 낸다는 것은 서비스가 어느정도 실패를 허용할 수 있는지 밝혀내는 것으로 비지니스와 관련이 있다.
이는 비지니스 목표를 기반으로 엔지니어링 목표가 될 수 있는 명시적인 서비스 제공 수준을 만들어 내는 것을 의미한다.
서비스의 위험 감수 한계를 평하할 때 목표 가용성 수준, 실패의 종류, 비용을 고려해야 한다.
커스터머 서비스와 인프라스트럭쳐 서비스의 위험 내성의 양상은 조금 다르다.

#### Identifying the Risk Tolerance of Consumer Services
커스터머 서비스(ex, 구글맵, 구글독)에서는 제품개발팀의 비지니스 오너로 활동한다. 
프러덕트 메니저는 마켓 플레이스에서 프러덕트의 성공을 위해 유저와 비지니스에 대해서 이해할 책임이 있는데, 프러덕트 팀에서 신뢰성 요구사항을 논의한다.

목표 가용성 수준: 경쟁서비스 서비스의 유무료 여부 등에 따라서 결정된다.
실패의 종류: 데이터의 종류에 따라 취해야 하는 행동이 달라진다. 개인정보와 관련된 실패는 장애 기간이 길어지더라도 철저한 점검이 필요하다.
비용: 신뢰성과 그에 따른 수익을 비교해서 신뢰성을 올리는데 필요한 비용이, 신뢰성을 올렸을 때 발생하는 추가적인 수익보다 적다면 시도해 볼만하다. 
하지만 이러한 신뢰성과 수익에 대한 함수 도출은 쉽지 않다.
다른 메트릭: 가용성을 제외한 메트릭도 위험 감수 한계를 평가할 때 도움이 될 수 있다. 예를들어 어떤 서비스는 지연시간이 중요하지만, 다른 서비스에서는 중요하지 않다.
느슨한 지연시간 요구사항을 밝혀내면 운영비용을 절감 할 수 있다. 

#### Identifying the Risk Tolerance of Infrastructure Services
인프라스트럭처 서비스는 인프라스트럭쳐 서비스(ex, 빅테이블)의 경우 클라이언트가 다양하고 요구사항도 다양하다. 
예를들어 산출량이 중요한 유저도 있고, 지연시간이 중요한 유저도 있다.
저지연을 요구하는 사용자는 요청 큐가 계속해서 비어있기를 원하고 , 산출량을 원하는 사용자 전체 처리의 효율성을 위해서 항상 큐가 가득차 있기을 원한다.
이처럼 상반된 목표를 가지고 있는 경우.
서로 다른 요구사항을 만족하는 복수의 클러스터로 서비스 수준을 제공하는것으로 이 문제를 해결 할 수 있다.

### Motivation for Error Budgets (오류 예산의 도입 배경)

제품 개발팀의 실적은 얼마나 빨리 새로운 기능을 출시하는 것이다. 반면 SRE 의 실적은 신뢰성에 기반된다.
새로운 기능의 출시는 신뢰성을 떨어뜨리고 이 두 동기는 충돌한다.
 
결국 기능의 출시 속도는 두팀의 협상 결과로 비공식적인 균형에 의해 정해지나, 이것이 최적화 되었는지는 알 수 없다.
구글에서는 목표는 두 팀의 동의하는 객관적인 지표 정해서 재현가능한 방식으로 협상을 이끄는데 그 지표를 사용하는 것이다.
결정은 데이터에 기반할 수록 좋다.

#### Forming Your Error Budget
객관적인 데이터를 통해 의사결정을 하기 위해서 두팀은 분기별로 SLO 와 오류예산을 공동으로 정의한다.
이 지표를 사용함으로써 허용가능한 리스크의 수준을 합리적으로 정할 수 있다.
예를들면 오류예산은 다음과 같이 활용 될 수 있다.
한 분기의 요청 성공률의 SLO 99.999% 인 경우 오류예산은 0.001% 이다.
만약 어떤 문제가 한 분기의 예상쿼리의 0.0002% 를 실패하게 만든다면 오류예산은 20% 가 사용된 것이다.

#### Benefits
오류예산 SRE 와 제품 개발팀의 동인을 일치 시키고 공동의 소유권을 강조한다.
제품 개발팀은 오류예산을 활용한 제어 루프를 통해 릴리즈 속도를 조절한다.
즉 SLO 가 충족되는한 릴리즈는 계속 될 수 있다.
제품 개발팀은 계속해서 새로운 기능을 릴리즈하기 위해서라도 신뢰성을 고려하게 된다.
에러 버짓은 구체적인 수치로써 여러 팀에 걸쳐서 의사소통을 원할하게 하며 출시 속도를 결정하는데 도움을 준다.

--------------------

## 서비스 수준 목표 (Service Level Objectives)

서비스에 있어 진정으로 중요한 동작이 무엇인지, 그리고 그것을 어떻게 측정하고 평가할지를 이해하지 못한다면 서비스를 제대로 관리하는 것은 불가능하다. 
이러한 목적을 달성하기 위해, 내부 API를 사용하든 공개된 제품을 사용하든 상관없이 사용자에게 특정 수준의 서비스를 정의하고 제공해야 한다.

직관, 경험, 그리고 사용자가 원하는 바에 대한 이해를 바탕으로 서비스 수준 지표(SLI), 목표(SLO), 그리고 계약(SLA)를 정의한다. 
이러한 측정 기준은 중요한 메트릭의 기본 속성, 그 메트릭이 가져야 할 값, 그리고 기대한 수준의 서비스를 제공하지 못할 경우의 대응 방안을 설명한다. 
궁극적으로 적절한 메트릭을 선택하는 것은 문제가 발생했을 때 올바른 조치를 유도하며, SRE 팀이 서비스가 정상적으로 운영되고 있음을 확신할 수 있도록 도움을 준다.

### Service Level Terminology
#### Indicators(지표)
SLI 는 제공 되는 서비스 수준의 어떤 측면을 정밀하게 정의한 정량적인 측정(measure) 이다. (척도가 아니라 측정값 그 자체를 말하는듯)
측정값들은 종종 비율, 평균 등으로 집약된다. 
availability 는 SLI 중에 하나 이다.

#### Objectives(목표)
SLO 는 SLI 로써 측정된 서비스 수준에 대한 목표 값 이다.
목표값은 다음 처럼 나타난다. SLI ≤ target
SLO 를 공개하는 것으로 유저가 서비스에대한 자신의 믿음을 만들어내는 것을 방지할 수 있다.

※ Chubby 케이스 스터디: SLO 를 과도하게 초과해서 Chubby 에 장애가 생기 지않을 거라는 잘못된 믿음이 생겼다. 
SLO 를 달성하는 수준에서 의도적으로 장애를 만듬으로써 이러한 비합리적인 의존을 제거할 수 있었다.

#### Agreements
SLA 는 SLO 가 충족되거나 그러지 못했을 경우의 결과를 포함 하고 있는 유저와의 계약이다.
Google Search 는 SLA 가 없다. 

### Indicators in Practice (지표의 적용사례)

#### What Do You and Your Users Care About?
모니터링 시스템의 모든 수치를 SLI 로 사용할 수는 없다. 사용자들이 무엇을 원하는지 이해해서 지표를 신중하게 선택해야,
적절하게 지표들에 주의를 기울일 수 있다.
소수의 대표적인 지표만으로도 시스템의 상태를 평가하는데 충분하다. 

서비스들은 중요하게 여기는 SLI의 관점에서 몇 가지 넓은 범주로 나뉘는 경향이 있다:
- 유저와 접하는 시스템: availability, latency, throughput
- 스토리지 시스템: latency, availability, durability
- 빅데이터 시스템(데이터 프로세싱 파이프라인): throughput, end-to-end latency
- 모든 시스템: correctness(정확성), 단 이것은 SRE 과 관리하는 지표는 아니다.

#### Collecting Indicators
대부분 서버사이드에서 측정하지만, 이것으로 드러나지 않는 문제도 있기때문에 일부 시스템은 클라이언트 측에서도 측정해야 한다.

#### Aggregation (집계)
단순함과 사용성을 위해서 낮은 레벨의 측정을 집계한다. Request per Second 같은 단순한 지표도, 측정 창(1 Second) 안에서의 데이터의 집계이다.
매 짝수초마다 200 개의 요청이 있는 서버와, 매초마다 100 개의 요청이 있는 서버의 RPS는 같으나 전자가 동시에 일어나는 요청이 더 크다.
이처럼 평균값을 사용하는 것은 맹점이 있으며, 분포(distributions) 를 사용하는 것이 더 바람직 하다.

#### Standardize Indicators (지표 표준화)
SLI 에 대해서 공통의 정의를 표준화 해야한다. 재사용 가능한 SLI 의 템플릿을 만들어서 사용하는 것도 좋다.


### Objective in Practice (목표의 적용사례)
목표를 먼저 설정하고 그것에서 지표를 도출하는 방법이 도움이 될 수 있다.

#### Defining Objectives (목표 정의하기)
명확함을 위해서 목표치는 그것들이 어떻게 측정되고 그것들이 어떤 조건에서 유효한지 특정지어야 한다.
- 99% (1분 간의 평균) GET RPC 콜은 100ms 이내에 끝나야한다. (측정은 백엔드 서버이다.)
- 90% GET PRC 콜은 1ms 이내에 끝나야 한다.
- 99.9% GET PRC 콜은 100ms 이내에 끝나야 한다.
합리적인 SLO 를 설정하고 그로 인해 허용되는 에러버짓의 소진을 정기적으로 추적하는게 바람직 하다.

#### Choosing Targets (목표 선택)
SLO 는 제품과 비지니스에 영향을 준다. 인력, 출시 시점, 하드웨어 가용성, 예산등의 제약 사항 속에서 제품은 어떤 속성을 다른 속성과 트레이드 오프해야 하는 경우도 있다.
SRE 는 이 과정에 참여해서 위험도와 실현가능성에 대해서 조언 해야한다.
- Don't pick a target based on current performance
- Keep it Simple
- Avoid absolutes: 개발 / 운영 비용, 실제로 유저가 원하는 안정성을 무시하고 완전무결함을 추구해서는 안된다.
- Have as Few SLOs as possible
- Perfection can wait: 비교적 느슨한 목표부터 시스템에 대해서 배운것을 토대로 목표를 다시 설정 할 수 있다닌걸 기억해야 한다.

#### Control Measures (제어 수단)
SLO/SLO 는 다음과 같이 관리 시스템에서 사용되는 컨트롤 루프에서 중요한 요소이다.
1.시스템의 SLI 를 측정하고 감시한다.
2.SLI 와 SLO 를 비교해서 행동이 필요한지 아닌지 결정한다.
3.행동이 필요한 경우 목표를 달성하기 위해서 무엇을 해야하는지 밝힌다.
4.행동을 취한다.
예를 들어서 2 단계에서 latency 가 증가 하고 있고 수시간 내에 SLO 를 위반하게 된다면,
3 단계 에서는 cpu 리소스가 부족하다는 가설을 세우고 그것을 테스트 하는 행동이 포함될 것 이다.
SLO 가 없다면 이러한 행동이 필요한지 알 수가 없다.

#### SLOs Set Expectation (SLO 는 기대를 설정한다.)
SLO 의 유저의 기대를 설정한다. 제품이 그들의 유즈케이스에 적절한지 이해하기 위해서 그들이 무엇을 개대할 수 있는지 알고 싶어한다.
예를들어 사진 공유 웹사이트를 만드려고 하는 팀은, 가용성을 조금 희생하더라고 내구성(durability) 를 요구할 것이다.
유저가 현실적인 기대를 설정할 수 있도록 하기 위해서 다음과 같은 전략을 사용하는 것을 고려할 수 있다.
- Keep a Safety Margin: 외부 SLO 를 더 빡빡한 내부 SLO 를 설정하라. 이는 유연한 시스템 개선을 가능하게 힌다.
- Don't Overachieve: SLO 보다 더 높은 성능을 제공하면 잘못된 기대를 하고 그것에 의존하게 할 것이다. 이를 방지하기 위해서 계속적인 트롤링으로 SLO 를 과하게 초과하지 않도록 하는 전력을 사용할 수 있다.

시스템이 얼마나 기대를 잘 충족시키는지 이해 하는 것은 어느 것을 개선하는데 리소스를 투자할지 결정하는 것을 도와준다.

### Agreements in Practices
SLA 를 작성하는데는 비지니스와 법률팀이 위반에 대한 결과를 정해야 한다.
SRE 는 SLA 에 포함된 SLO 의 이해를 돕는 것이다.  
SLO 를 만들때의 조언들은 SLA 에도 적용가능하나 SLA 는 변경하기가 더욱 힘들다.

--------------------

## 반복작업 제거하기 (Eliminating Toil)
SRE 의 가장 중요한 일중 하나는 귀찮은일을 제거하는 것 이다. 
SRE 는 toil 을 서비스가 성장할때 리니어하게 증가하는, 오래 지속되는 가치를 만들지 않는 반복적인 운영업무를 의미한다.

### Toil Defined
운영자의 잡일이나, 지저분한 일은 toil 이 아니다. 운영자의 잡일은 서비서의 운과 직접적으로 묶여있지 않는 오버헤드이다. (팀 미팅, 목표 정하기, HR 서류작업)
지저분한 일은 장기적인 가치를 가진다. 예를들어 경고 설정 정리나 클러스터 정리 같은건 지저분한 일일 수는 있으나 toil 은 아니다.
toil 은 수동이고, 반복적이고, 자동화 할 수 있고, 전술적이고, 지속되는 가치가 없고, 서비스가 성장함에 따라 선형적으로 성장하는 일이다.
toil 로 간주되는 일이 모든 속성을 가지지는 않고, 아래 기술한 것들중 한 두가지에 해당하면 toil 이라고 볼 수 있다. 

- Manual: 스크립트를 실행하는 것은 각각의 단계를 수동으로 실행하는 것 보다 빠르다. 하지만 스크립트를 실행시키는 것 또한 toil time 이다.
- Repetitive: 한두번 일을 하는것은 toil 이 아니다. 
- Automatable: 기계가 그 작업을 사람만큼 잘 할 수 있다면, 그 작업은 toil 이다. 사람의 판단이 필수적이라면 toil 이 아니다.
- Tactical: toil 은 전략적이거나 사전적이 아니라 인터럽트 주도적이다. 호출기 경고를 다루는 것은 toil 이다. 이것을 완전히 제거할 수는 없으나. 계속 해서 최소화 하기 위해서 노력해야 한다.
- No enduring value: 어떤 작업을 마친 후에도 서비스의 상태가 이전과 동일하다면 그것은 toil 일 확률이 높다. 서비스에 영구적인 개선을 가지고 온다면 toil 이 아니다. 
legacy-code 와 설정을 파고들어서 이것들을 바로잡는 것은 지저분한(Grunt) 일 이지만 toil 이 아니다.
- O(n) with service growth: 작업과 관련된 일이 서비스가 성장함에 따라 선형적으로 같이 증가하면 그것은 toil 이다.
이상적으로 설계되고 관리되는 서비스는 작업량이 늘지 않는 상태 또는 리소스 추가 만으로 한자릿수 이상 성장 할 수 있어야 한다.

### Why Less Toil Is Better
toil 은 방치하면 계속해서 증가한다. toil 을 줄이는 엔지니어링을 수행하기 때문에 인력과 서비스의 규모의 선형관계의 기울기를 낮게 유지할 수 있다.
#### Calculating Toil
온콜 근무중에는 toil 을 감당해야 한다. 6명이서 한 주는 프라이머리 온콜러, 다른 한주는 세컨더리 온콜러로 일하면 6주 중에 2주, 
33% 가 운영업무를 하는데 사용하는 시간이 된다.
통계에 따르면 toil 의 원천 되는것의 크기는 인터럽트, 그리고 릴리즈 작업 순이다.

### What Qualifies as Engineering
엔지니어링은 본질적으로 인간의 판단이 필요하며 지속되는 개선을 만든다.
SRE 의 활동은 일반적으로 다음과 같은 범주에 속한다.
- Software Engineering: 코드작성 설계, 문서화 기능추가 
- System Engineering: 설정변경, 문서화, 모니터링 셋업 및 업데이트 같은 지속되는 일발성 노력
- Toil: 서비스 운영과 직접적으로 묶여있는 반복적인 작업
- Overhead: 서비스운영과 직접적으로 묶여있지 않은 관리업무, 인사(채용/평가), 교육등

※ Software Engineering 를 공정으로 보기 보다는, 소프트웨어를 만드는 과정 전체를 Software Engineering의 범주에 포함시켜서 생각하자. (self-contained)

### Is Toil Always Bad?
toil 은 무조건 적으로 나쁜건 아니다. 어느정도의 toil 은 피할 수 없다. 양이 많을때 toil 은 독이 된다.
- Career stagnation: 프로젝트를 하지 않으면 커리어가 발전하지 않는다.
- Low morale: 어느 정도의 toil 을 견딜 수 있는지는 사람마다 다르며, 양이 너무 많아지면 사기가 꺾인다.
- Create confusion: SRE 팀은 engineering 조직이지만 역할에 대한 명확학 메세지가 저해된다.
- Slows progress: 제품 개발속도가 줄어든다. 
- Sets precedent(선례설정): 대응관계의 제품 개발팀이 잘못된 기대를 하게되고, 다른 sre 와 dev 팀의 관계에도 영향을 미친다.
- Promotes attrition(이탈촉진): 뛰어난 엔지니어가 떠날 수도 있다.  
- Causes breach of faith(신뢰를 잃음): SRE 가 기본적으로 엔지니어링 롤 이라는 기대를 배신한다.  

### Conclusion
매주 약간의 toil 을 제거 하는데 힘을 쓴다면, 그 에너지를 엔지니어링에 쏟을 수 있다. 
--------------------

## 분산시스템 감시 (Monitoring Distributed Systems)
모니터를 하지 않으면 시스템에 무슨일이 일어나는지 알 수 없다.
### Definitions
- Monitoring: 시스템에 관한 실시간 정량 데이터를 수집, 처리, 집계, 시각화 하는 것.
- White-box monitoring: 시스탬의 내부로부터 노출되는 메트릭에 근거한 모니터링 ex) logs, 내부 통계를 내는 http 핸들러
- Black-box monitoring: 사용자가 보는 것 처럼 외부에 드러나는 행동을 테스팅 하는 것.
- Dashboard: 서비스의 코어 메트릭에 대한 요약뷰를 제공하는 어플리케이션, 현재 온콜러, 티켓큐 상태 같은 팀의 정보를 표시할 수도 있다.
- Alert: 사람에게 읽혀져야 하는 알림. alert 은 tickets, email alerts, pages 로 다시 분류된다.
- Root cause: 소프트웨어나 휴먼시스템에 있는 결함으로 이것이 고쳐진다면 다시는 이 이벤트가 일어나지 않을거라고 확신할 수 있는 것.
- Node and machine: 물리적인 서버, 가상머신, 컨테이너에서 실행중인 하나의 인스턴스를 가르키며 두 용어는 서로 바꿔쓸 수 있다.
- Push: 서비스의 소프트웨어나 설정에 가하는 변경
### Why Monitor?
- Analyzing long-term trends(장기적인 트랜드 분석): 내 db 가 얼마나 빠르게 성장하는지, 유저수는 얼마나 빠르게 성장하는지
- Comparing over time or experiment groups: 전 주보다 내 사이트가 느려졌는지 빨라졌는지, 어떤게 캐시 히트레이트가 높은지
- Altering: 무언가 망가졌고 누군가 바로 그것을 고칠 필요가 있다. 또는 무언가가 곧 망가지니 누군가 그것을 살펴볼 필요가 있다.
- Building dashboards: 대쉬보느는 서비스에 대한 기본적인 질문에 대해서 답해야한다. 이를 위해서는 모니터링이 필요하다. 
- Conducting ad hoc retrospective analysis (과거 데이터 분석, 디버깅): 지연시간이 늘어났는데 동시에 또 무슨일이 일어났는지

비지니스 분석과, 보안 균열 분석에도 사용된다. 
모니터링 과 경고는 시스템이 자체적으로 그것을 수리할 수 없을 때, 그것이 언제 망가졌고 무엇이 망가질것 인지 알려준다.
경고가 있다면 사람이 실제로 그것에 대해서 조사한 후, 문제를 완화하고 근본 원인을 찾아야 한다.
사람을 호출하는것은 아주큰 비용이 드는것 임으로 효과적인 경고 시스템은 신호는 좋고 노이즈는 낮아야 한다.

### Setting Reasonable Expectations for Monitoring
- 최소한 1명의 스태핑이 필요하다.
- 심플하고 빠른 모니터링 시스템과 사후분석을 용이하게 하는 툴을 지향한다.  
- 경고는 의존계층을 가지지 않는다. 인프라가 지속적으로 리팩터링 되기 때문이며 만약 의존계층을 가진다면 가장 매우 안정적인 부분에만 의존한다.
- 문제발생, 경고, 분류, 디버깅이어지는 프로세스는 모든 팀 구성원이 이해할 수 있을 정도로 단순하고 명료해야 한다.
- 신호를 높이고 노이즈를 줄이기 위해서 호출기에 연결되는 모니터링 요소(경고 생성 규칙 및 실패에 대한 표현)는 단순하고 견고해야 한다.

### Symptoms Versus Causes
모니터링 시스템은 두가지 질문을 다뤄(해결해야)야 한다. 무엇이 망가졌고 왜 망가졌는가?
무엇이 부서졌는가는 증상이고, 왜 망가졌는가는 원인을 나타낸다.

### Black-box versus White-box
화이트박스 모니터링을 주로 사용하고, 블랙박스 모니터링은 적지만 핵심적인 용도로 사용한다.
블랙박스 모니터링은 이미 일어난 증상 중심이며, 화이트박스 모니터링은 시스탬 내부 계측으로 예측 중심이다.
다층 시스템에서 누군가으 증상은 누군가의 원인이 된다.
디버깅에 화이트박스 모니터링은 필수적이며, 호출에는 블랙박스 모니터링이 유용하다.

### The Four Golden Signals (4가지 핵심 신호)
모니터링의 핵심 신호는 지연시간, 트래픽, 에러, 포화도 이다.
- Latency: 서비스가 요청을 접수하는데 걸리는 시간. 지연시간을 측정할 때, 성공한 요청의 지연시간과 실패한 요청의 지연시간을 따로 측정해야 한다.
- Traffic: 시스템에 얼마나 많은 수요가 있는지 측정한 것. 시스템의 특정한 메트릭으로 측정된다 예)초당 http 요청
- Errors: 요청 실패 빈도. 명시적인것과 암시적인것이 모두 포함된다.LB에서는 500과 같은 명시적인 실패는 잘 감지 할 수 있지만, 200에 잘못된 컨텐츠를 전달하는 경우에 대한 감지는 E2E 테스트가 필요하다.
- Saturation(포화): 서비스가 얼마나 찼는지. 시스템의 일부에 대한 측정으로 메모리와 같은 가장 제약된 리소스 강조한다. 100% 활용도(utilization) 전에 성능이 저하됨으로 목표 활용도를 정의해야 한다. 
네가지 신호만 층정하고 신호에 문제가 있을때 사람을 호출하도록 하면 최소한 어느정도까지는 모니터링에 의해서 서비스가 커버된다고 볼 수 있다.

### Worrying About Your Tail (꼬리지연시간에 대해 걱정하기)
평균값에는 맹점이 있다. 분포도 같이 봐야한다. 백엔드의 99% 의 가장 느린 지연시간이 프론트엔드에서의 응답시간의 중앙값이 되버릴 수도 있다.
도수 분포도를 사용하는것이 요청의 분포를 시각화하는 쉬운 방법이다.

### Choosing an Appropriate Resolution for Measurements(측정을 위한 적절한 해상도 선택하기)
시스템의 다른 측면은 다른 수준의 입도로 측정되어야 한다.
높은 입도의 측정은 당연히 그만큼 더 큰 비용이 든다. 높은 해상도를 요구하지만 실시간일 필요가 없는 경우는
내부에서의 측정은 빈번하게 하고, 외부에서 더 낮은 빈도로 측정값을 모으고 집계하는 전략을 사용할 수도 있다.

### As Simple as Possible, No Simpler(가능한 단순하게, 하지만 너무 단순하지는 않게)
모니터링 시스템은 복잡해지기 쉽다. 따라서 다음과 같은 가이드라인을 염두해서 단순함에 초점을 두고 설계해야한다.
- 자주 실제 사고를 잡아내는 규칙은 가능한 단순하고 예측가능하고 신뢰할 수 있어야 한다.
- 거의 사용되지 않는 경고 설정은 삭제하는걸 고려해야 한다.
- 수집되지만 대쉬보드에 표시되지 않거나 경고에 사용되지 않는 신호는 삭제되어야 한다.
모통 모니터링 시스템은 독립적인 시스템으로 잘 동작한다. 더 다향한 기능을 통합하고 싶을 수도 있지만 좋은 선택이 아니다.
명확하고 단순하며 느슨하게 결합된 통합지점으로 모니터링 시스템을 유지하는 것이 바람직 하다.

### Tying These Principles Together
모니터링 및 경고에 대한 철학을 적용해서 모니터링 및 경고에 관한 룰을 만들때 다음과 같은 질문을 통해 거짓 양성 및 비효율적인 호출을 피할 수 있다.
- 이 룰이, 이 룰이 아니라면 탐지할 수 없는 긴급하고 유저가 볼수 있는 조건을 탐지하는가?
- 이 경고를 내가 무시할 수 있을까? 언제 그리고 왜 이 경고를 무시할 수 있게될까? 이러한 시나리오를 방지하려면 어떻게 해야할까?
- 이 경고가 유저가 나쁜 영향을 받고 있다는걸 나타내는가? 사용자에게 영향을 주지 않는 경우가 있다면 필터링 되어야 하지 않을까?
- 이 경고에 대한 반응으로 내가 조치를 취할 수 있는가? 조치는 긴급한가 아침까지 기다릴수 있는가? 자동해도 안전한가? 장기적인 해결책인가? 아니면 임시 방편인가? 
- 이 이슈에 대해서 다른사람들도 호출을 받고 있는가? 호출을 받지 않아도 되는 사람이 있지는 않을까?  

다음은 호출에 대한 기초 철학을 반영한다.
- 호출기가 울릴때, 긴박감을 가져야한다. 하지만 그런 반응을 할 수 있는 횟수는 제한적이다.
- 모든 호출은 조치할 수 있어야 한다.
- 모든 호출의 응답은 사람의 판단력이나 지능이 필요한 상황이어야 한다. 단순히 기계적인 응답으로 충분하다면 그것은 호출일 필요가 없다.
- 호출은 새로운 문제이거나 전에 없던 사건이어야 한다.  

### Monitoring for the Long Term (장기적인 관점에서의 모니터링)
지금은 가끔씩 일어나는 경고는 나중에는 빈번해 질 수 있다. 이때 원인을 제거하거나, 경고에 대한 대응을 자동화 해야 한다.
모니터링에 대한 결정은 장기적인 목표를 고려해야한다. 따라서 시스템의 장기적인 전망을 개선하기 위해서 단기적으로 가용성이나 성능저하를 감수하는 경우도 발생한다.
- Bigtable SRE: A Tale of Over-Altering
이미 알려진 인프라 내부문제로 SLO 에 근접하거나, 초과했을 때 경고가 발생했는데 너무 자주 알림이 발생해서,
실제로 조치를 취할 수 있는 알림을 찾는데 많은 시간을 사용했다. 대부분의 알림은 이미 알려진 인프라 내부문제에 의한것으로 긴급하지 않았다.
이를 해결하기 위해서 다음의 세가지 시책을 병행했다. 
첫째로 실제로 Bigtable의 성능을 개선작업을 했다.
둘째로 SLO 를 임시적으로 완했다. 
샛째로 이메일 알림을 일시적으로 비활성화 했다. 알림이 너무 많아서 그것을 다 분석하는 것이 불가능 했기 때문이다.
이러한 전략으로 Bigtable의 근본적인 문제를 해결할 수 있는 여유시간을 확보하고, on-call 엔지니어는 실제로 업무에 집중할 수 있었다.

- Gmail: Predicable, Scriptable Responses from Humans
gmail 에서는 Workqueue 라는 시스템을 개조해서 사용하고 있었다. Workqueue 에 의해서 개별 테스크의 스케쥴이 해제 되었을 때  
경고가 발생하도록 설정 했는데 이것은 지속가능한 방식이 아니었다.
사용자에게 미치는 영향을 최소화 하기 위해서 팀에서는 임시로 문제를 감지하고 다시 스케쥴링하는 과정을 자동화 하는것을 논의 했다.
팀의 일각에서는 이러한 임시방편이 근본적인 문제의 해결을 지연시키게 될까봐 우려했는데 이는 현실적인 우려였다.
실제로 문제를 해결하기 보다는 임시 패치를 거듭하다보면 기술부채가 쌓이기 쉽다.
이때 리더는 임시적인 조치를 한 후에도 장기적인 해결책을 추구하도록 해야한다.
반복적으로 알고리적으로 처리되는 호출 위험 신호로 봐야한다. 
이러한 것들을 자동화 하는것또한 꺼린다면 이는 팀이 기술부채를 해결할 자신이 없다는 신호 일 수 있다.

#### The Long Run
두 캐이스 스터디의 공통된 주제는 단기적인 가용성과 장기적인 가용성간의 긴장이다.
불안정한 시스템에서 높은 가용성을 억지로 달성 할 수 있지만, 이러한 해결은 미봉책이며 
소수의 히어로 개발자에게 의존하는 위험을 낳을 수 있다. 따라서 통제된 범위 내에서 단기적인 가용성 저하를 감수하는 것이 장기적인 안정성을 위한 전략적 선택이 될 수 있다.
호출 사건을 고립된 이벤트로 보지 않고 빈도와 패턴으로 시스템의 건전성을 같이 보는 관점을 가져야 한다.

### Conclusion
모니터링이 뭔지, 왜 하는지 그밖에 주의 해야할 점들에 대해 소개하고, 이것들은 반영한 모니터링 시스템을 구축하기 위한 질문도 살펴봤다.
단기적인 가용성과 장기적인 가용성사이에 긴장이 있고, 단기적인 조치를 취하더라도 장기적인 관점에서 문제 해결이 이루어져야 한다는 걸 배웠다.

건전한 모니터링 및 경고 파이프라인은 단순하고 이해하기 쉬어야 한다.
호출은 증상 중심으로 설정되고, 내부계측은 디버깅 수단으로 활용되는게 이상적이다.
대시보드는 연속적인 관점을 제공함으로써 지속적인 경미한 문제들을 감시할수 있게 한다.

장기간에 걸쳐서 제품을 관리하기 위해서는 다음과 같은 것들이 필요하다.
- 실제 증상이나 임박한 문제에 대해서만 경고를 설정하는 것 
- 현실적으로 달성가능한 목표를 채택하는 것
- 모니터링이 신속한 진단을 보장하도록 하는것


--------------------

## 구글에서의 자동화의 진화 (The Evolution of Automation at Google)
필요한 곳에 자동화를 도입해야 한다. 신중한 고려 없이 잘못된 방향으로 자동화를 도입하면 자동화가 문제를 늘릴 수도 있다.
대부분의 상황에서 수동작업보다 소프트웨어 기반의 자동화가 낫지만, 이상적으로는 자율적인 시스템을 추구해야 한다.

### The Value of Automation
- Consistency:   
  사람은 기계만큼 일관되게 작업 할 수 없다. 일관성 부족은 실수로 이어지고 이는 곧 신뢰성 문제를 의미한다. 
  명확히 정의된 작업을 안정적이고 일관되게 수행할 수 있다는 점이 자동화의 장점이다.
- A Platform:   
  자동화된 시스템은 확장될 수 있는 플랫폼으로 기능한다. 플랫폼은 실수를 중앙 집중화 함으로(중복을 제거한다.)  
  코드에서 버그를 고치면 문제가 영구적으로 해결되게 할 수 있다. 또한 플랫폼은 더 쉽게 작업을 확장 할 수 있다.
- Faster Repairs(더 빠른 복구):   
  시스템에서 자주 발생하는 장애를 해결하는데 자동화를 사용하면 평균 복구시간이 줄어든다.  
  문제가 발생하자마자 자동으로 감지하고 해결하는 자동화는 시스템의 전체적인 운영비용을 낮춘다. (문제가 유저에게 보여지는것, 엔지니어에게 발생하는 인터럽트등의 비용)
- Faster Action(빠른 대응): 대규모 인프라 환경에서는 사람보다 기계가 훨씬 빠르게 반응할 수 있다. 장애조치 같이 특정 어플리케이션에 대한 동작이 명확히 정의되어 있는경우,
  이것을 사람이 간헐적으로 실행시키는것 자체가 비효율이다. 규모가 커지면 수동으로 운영할 수 있는 한계를 넘어서 자동화가 필수적인 인프라가 되는 시점이 존재한다.
- Time Saving:  
  자동화를 해놓으면 나 포함 다른 엔지니어의 시간도 절약하게 된다. 
  "특정 작업을 수동으로 반복하지 않도록 자동화하는 것이 실제로 시간 대비 가치가 있는가?" 라는 질문이 떠오르지만, 
  누구라도 실행할 수 있게 작업을 자동화로 캡슐화 해 놓으면, 다른 누군가 그 자동화를 사용할 때마다 시간이 절약된다.
  작업을 작업자로 부터 분리해 내는 패턴은 매우 유용한 패턴으로 누구든지 일관되게 작업을 수행할 수 있기 때문에 지식이나 경험의 격차도 줄일 수 있다.(마치 체크리스트) 

### The Value for Google SRE (구글 SRE 에서의 가치)
구글은 지구적인 규모의 서비스를 운용하기 때문에 일관성, 속도, 신뢰성이 트레이트오프에서 더 큰 메리트가 되고 자동화를 선호한다.
구글은 자동화된 시스템을 구축함으로써 전 스택에 대한 통제권을 가질 수 있게 되었다.
구글은 플랫폼을 만들기로 선택했고, 이 선택은 관리용이성과 확장성을 위한 필수적인 선택으로 보고 있다. (플랫폼을 만드는 것도 자동화다.)

### The Use Cases for Automation
여기에서 자동화란 소프트웨어를 대상으로 동작하는 메타 소프트웨어를 의미한다.
자동화의 예는 다음과 같다.
- 유저 계정 작성
- 클러스터 턴업 및 턴다운 (턴업 턴다운: 용량 줄이기 늘리)
- 소프트웨어 또는 하드웨어의 서치 준비 및 폐기 
- 새로운 소프트웨어 버전의 롤아웃 (롤아웃: 단계적인 배포)
- 러타임 설정 변경
- 의존성 변경

#### Google SRE's Use Cases for Automation
SRE 에서 말하는 자동화는 시스템의 생명주기를 관리하는 자동화를 말한다. 

자동화에는 다양한 추상화 수준의 도구를 사용한다. 
예를들면 Perl 과 같은 언어는 POSIX 수준의 추상화를 제공하고,
Chef 와 같은 서비스는 고수준의 엔티티를 조작할 수 있는 사전에 정의된 추상화를 제공한다.

여기에서 발생하는 트레이드오프틑 전형적이다.
고수준 추상화는 관리하고 이해하기 쉽지만, 추상화 누수(Leaky abstraction) 를 만나면,
반복적이고 일관 없이 실패 한다. 
예를들어 클러스터에 바이너리를 배포하는 것이 원자적이라고 생각할 수 있으나,
실제로는 클러스터간 네트워크가 실패할 수도 있고, 머신이 고장날 수도 있으며, 관리계층과의 통신이 실패할 수도 있다.
또는 바이너리가 배포되었으나 시작되지 않는 경우도 있다.
이러한 결과를 성공적으로 모델링하는 추상화는 드물며, 대부분의 경우 사람의 개입을 요구하게 된다.
최악의 경우는 아무것도 결과 조차 보고 하지 않는다.

SRE는 자동화 분야에 여러 철학과 제품을 가지고 있다. 어떤 것은 고수준 엔티티의 모델링이 없는 툴이고,
일부는 서비스 배포를 추상적인 수준에서 설명하는 언어처럼 보인다.
후자는 일반적으로 전자보다 재사용이 가능하며 공통 플랫폼으로 기능한다.
※ [Leaky abstraction](https://en.wikipedia.org/wiki/Leaky_abstraction): 
복잡한 시스템의 세부사항을 감추고 단순화 하려는 추상화가 완전히 기능하지 못해서, 일부 구현 세부사항이 새어나오는 설계 결함.
사용자는 시스템을 효과적으로 사용하거나 문제를 해결하기 위해서 원래 숨기려고 했던 복잡성을 일부 이해해야한 한다.
 

#### A Hierarchy of Automation Classes (자동화 위계의 분류)





--------------------

## 릴리즈 엔지니어링 (Release Engineering)

## 단순함 (Simplicity)
잘 작동하는 복잡한 시스템은 반드시 잘 작동하는 단순한 시스템에서 진화해온 것이다.





