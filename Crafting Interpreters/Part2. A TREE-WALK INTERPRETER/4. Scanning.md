# Scanning
Scanner 는 raw source code 문자열을 문법을 구성하는 의미있는 단위인 token 들로 바꾼다. (무언가를 포현하는 가장 작은 시퀸스는 렉심(어휘?)이다.)
스캐닝에서는 maximal munch 라는 원칙이 적용된다. 이것은 lexical grammar rules 두가지가 코드 청크와 매칭될 때, 가장 많은 문자가 매치되는 룰이 이긴다는 원칙이다.   
예약어(reserved word)는 식별자(identifier) 인데, 언어가 자체적으로 사용하기 위해서 정해둔 것이다.

# 문단별 흥미로운 내용
## The Interpreter Framework
- the basic shape of the interpreter ≒ the interpreter framework ≒ 개발자의 코드가 동작하는 토대 
- Control-D 는 end-of-file signal 을 프로그램에 보낸다.
- good command line citizen 은 non-zero exit code 와 함께 프로그램을 종료한다.
- 스캐너가 에러 리포팅 루틴을 가지지 않도록 한 이유는, 오류를 생성하는 코드와 그것을 보고하는 코드를 분리하는 것이 좋은 엔지니어링 관행이다. (에러 보고는 추상화를 통해 여러 구체적인 채널이 될 수도 있다.)  

## Lexems and Tokens
- Our job is to scan through the list of characters and group them together into the smallest sequences that still represent something. Each of these blobs of characters is called a lexeme.
- When we take the lexeme and bundle it together with that other data, the result is a token.
- The parser could categorize tokens from the raw lexeme by comparing the strings, but that’s slow and kind of ugly. Instead, at the point that we recognize a lexeme, we also remember which kind of lexeme it represents.
- Literal: 코드내에 고정된 값 자체,

## Regular Language and Expressions
- The rules that determine how a particular language groups characters into lexemes are called its lexical grammar. 

## Recognizing Lexemes
- advance() is for input, addToken() is for output.
- match() is like a conditional advance()
- peek() only looks at the current unconsumed character, we have one character ahead. 

## Reserved Words and Identifiers
- 스캐닝에서는 maximal munch 라는 원칙이 적용된다. 이것은 lexical grammar rules 두가지가 코드 청크와 매칭될 때, 가장 많은 문자가 매치되는 룰이 이긴다는 원칙이다.
- Maximal munch means we can’t easily detect a reserved word until we’ve reached the end of what might instead be an identifier. 
  After all, a reserved word is an identifier, it’s just one that has been claimed by the language for its own use. That’s where the term reserved word comes from.
