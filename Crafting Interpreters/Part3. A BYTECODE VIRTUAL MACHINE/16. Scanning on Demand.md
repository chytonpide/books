# Scanning on Demand 요약
인터프리터를 실행 하기 위한 기본적인 구조를 만들고 스캐너를 구현했다.
jlox 에서는 전체 소스코드를 스캔한 후에 다음 단계로 넘어갔으나 clox 에서는 스캔결과물을 관리해야 하는 별도의 소스코드도 작성해야 한다.
이를 피하기 위해서 컴파일러가 토큰을 요구할때 바로 스캔하는 가장 간단한 해결책을 선택했다. (compile 에서 scanToken 의 루프를 돌린다.)
리터럴의 토큰의 경우 값을 만들지 않고, lexeme 을 그대로 저장했다가 상수를 저정할 수 있는 단계에서 값을 만든다.
키워드의 경우, 토큰을 구별하기 위해서 해시 테이블을 만드는건 너무 수고스러움으로 trie 라는 자료구조 (상태 머신의 한 종류) 를 사용한다.
이는 충분히 성능이 빠르다. v8 은 이 자료구조를 사용하느 구현으로 되어있는데, Java 스캐너는 해쉬테이블을 사용한다. (헤시 테이블 사용해도 상수시간, 병목지점은 아니다.) 


# 문단별 흥미로운 내용
## 16.1 Spinning Up the Interpreter
- fopen, malloc, fread 가 조용히 실패할 수 있으니 에러를 다뤄야한다. (fseek, ftell, rewind 도 이론적으로는 실패할 수 있지만 다루지 않는다. 적절한 수준 유지!)
### Opening the compilation pipeline
### The Scanner scans

## 16.2 A Token at a Time (한번에 토큰 하나씩)
- jlox 에서는 소스코드 전체를 스캔해서 token 리스트를 만들었다. C 에서 그렇게 하려면 자료구조 정의와 메모리 관리에 많은 코드를 작성해야 한다.
어떤 시점에서 컴파일러는 한두개의 토큰만을 필요로 함으로(lox의 문법은 하나의 토큰 앞서보기 만을 요구한다.) 가장 간단한 해결책은 컴파일러가 요구할때 까지 토큰을
스캔하지 않고 필요할때 값으로 넘겨주는 것 이다. 이렇게 하는것은 동적 할당같은건 필요없이 C 스택을 위에서 전달한다.
- jlox 에서는 스캐닝 에러를 직접 처리했지만, clox 에는 합성 에러 토큰을 컴파일러에 전달하고 이것을 전달 받아서 컴파일러가 에러 리커버리를 시작한다.
- 토큰의 표현에 있어서 jlox 에서 표현이 lexme 을 가지고 있었지만, clox 에서는 string 을 위해서 메모리 관리를 해야함으로, 소스코드의 포인터를 가지도록 한다. (당연히 메모리에 원본 소스코드가 계속 올라가있는 상태여야 한다.)
### Scanning tokens

## 16.3 A Lexical Grammar for Lox
### Whitespace
### Comments
- 주석은 행이 바뀌면서 끝난다. peek() 으로 행바뀜 문자를 확인하지만, 문자를 소비하지 않고, 다음 루프에서 행바뀜 문자를 소비한다.  
(skipWhitespace() 일부)
```c
for(;;) {
...
      case '\n':
        scanner.line++;
        advance();
        break;
      case '/':
        if(peekNext() == '/') {
          while (peek() != '\n' && !isAtEnd()) advance();
        } else {
          return;
        }
        break;
...
```
### Literal tokens
- Number and string tokens are special because they have a runtime value associated with them.
- jlox 에서는 리터럴을 스캔해서 토큰 클래스의 필드에 런타임 값을 저장했지만, clox 의 경우 그렇게 하려면 별도의 메모리 관리가 필요하다.
따리서 clox 에서는 lexeme 을 런타입 값으로 변경하는걸 미뤄서, 유저의 소스코드에 나타나는(메모리에 올라와있는 ) lexeme 을 저장한뒤
chunk 의 constant table 에 그것을 저장할 준비가 되어있을때 값으로 변경한다.

## 16.4 Identifiers and Keywords
- jlox 에서 키워드를 식별할 때는 그냥 map 을 썼다. clox 에서 이것을 위해서 hash table 을 만드는건 오버엔지니어링 이다.
따라서 키워드를 식별해 내기 위해서 상태 머신을 사용한다.
- 대부분의 자료구조는 문자 배열 자체를 보관한 다음, 검색을 빠르게 하기 위한 구조를 덧붙이지만 trie 라는 자료구조는 전체 문자열이 저장되는 일은 없다.
trie 는 finite state machine 의 특별한 경우라고도 할 수 있다. 
- DFA(a.k.a finite state machine) 으로도 lox 의 lexical 문법을 표현할 수 있다. Lex를 사용하면 lexical 문법에 대한 표현으로 DFA 구현체를 만들 수 있다.
- identifier() 에서 알파벳이나 숫자가 계속되는 동안만 string 을 잀는다. (Scanner 의 상태, start 랑 current 변경시킨다.)  
identifierType() 내의 checkKeyword() 의 `scanner.current - scanner.start == start + length` 에서 읽은 문자열과 키워드의 문자열의 크기를 먼저 비교함으로써,  
`vary`가 `var`로 keyword token 으로 스캔 되지 않고 identifier token 으로 스캔될 수 있다.   
```c
static Token identifier() {
  while (isAlpha(peek()) || isDigit(peek())) advance();
  return makeToken(identifierType());
}

...

static TokenType checkKeyword(int start, int length, const char* rest, TokenType type) {
  if (scanner.current - scanner.start == start + length && memcmp(scanner.start + start, rest, length) == 0) {
    return type;
  }

  return TOKEN_IDENTIFIER;
}
```
### Challenges
1. kotlin 은 중첩가능
2. java 는 scanner 레벨에서 다음 문자를 확인함
3. 장점: 키워드를 사용할 수 있다. 단점: 파서 구현이 어렵다. 혼란을 야기한다. (ide에서 하이라이트 안해주면 개발을 제대로 할 수 있을까?) 